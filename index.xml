<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Nick Karpov</title><link>https://nickkarpov.com/</link><description>Recent content on Nick Karpov</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Thu, 06 Mar 2025 01:00:00 +0000</lastBuildDate><atom:link href="https://nickkarpov.com/index.xml" rel="self" type="application/rss+xml"/><item><title>Token Alchemy</title><link>https://nickkarpov.com/2025/token-alchemy/</link><pubDate>Thu, 06 Mar 2025 01:00:00 +0000</pubDate><guid>https://nickkarpov.com/2025/token-alchemy/</guid><description>&lt;blockquote>
&lt;p>Dumb question but you know how LLMs output a distribution over tokens? Can you also give it a distribution as input?&lt;/p>&lt;/blockquote>
&lt;p>This question &lt;a href="https://x.com/ja3k_/status/1895638074576814552">on X&lt;/a> caught my eye and I decided to explore it further.&lt;/p>
&lt;p>Now, strictly speaking the answer is &lt;strong>no&lt;/strong>, LLMs don't take a distribution as an input: LLMs take a discrete sequence of tokens as an input. They are created by splitting the input text (&amp;quot;tokenizing&amp;quot;) into pieces (&amp;quot;tokens&amp;quot;) and looking up the vector representation of each of those pieces in an embedding matrix.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#007020;font-weight:bold">from&lt;/span> &lt;span style="color:#0e84b5;font-weight:bold">transformers&lt;/span> &lt;span style="color:#007020;font-weight:bold">import&lt;/span> AutoModelForCausalLM, AutoTokenizer
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tokenizer &lt;span style="color:#666">=&lt;/span> AutoTokenizer&lt;span style="color:#666">.&lt;/span>from_pretrained(&lt;span style="color:#4070a0">&amp;#34;microsoft/phi-2&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>input_text &lt;span style="color:#666">=&lt;/span> &lt;span style="color:#4070a0">&amp;#34;Dumb question&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tokens &lt;span style="color:#666">=&lt;/span> tokenizer(input_text, return_tensors&lt;span style="color:#666">=&lt;/span>&lt;span style="color:#4070a0">&amp;#34;pt&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>embeddings &lt;span style="color:#666">=&lt;/span> model&lt;span style="color:#666">.&lt;/span>get_input_embeddings()(tokens[&lt;span style="color:#4070a0">&amp;#34;input_ids&amp;#34;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#007020">print&lt;/span>(tokens)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#007020">print&lt;/span>(embeddings)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#60a0b0;font-style:italic">## output &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#60a0b0;font-style:italic"># Dumb question = 3 tokens, [ 35, 2178, 1808]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{&lt;span style="color:#4070a0">&amp;#39;input_ids&amp;#39;&lt;/span>: tensor([[ &lt;span style="color:#40a070">35&lt;/span>, &lt;span style="color:#40a070">2178&lt;/span>, &lt;span style="color:#40a070">1808&lt;/span>]]), &lt;span style="color:#4070a0">&amp;#39;attention_mask&amp;#39;&lt;/span>: tensor([[&lt;span style="color:#40a070">1&lt;/span>, &lt;span style="color:#40a070">1&lt;/span>, &lt;span style="color:#40a070">1&lt;/span>]])}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#60a0b0;font-style:italic"># Each token is represented by a vector&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tensor([[[ &lt;span style="color:#40a070">1.5388e-02&lt;/span>, &lt;span style="color:#666">-&lt;/span>&lt;span style="color:#40a070">5.5420e-02&lt;/span>, &lt;span style="color:#40a070">1.3306e-02&lt;/span>, &lt;span style="color:#666">...&lt;/span>, &lt;span style="color:#666">-&lt;/span>&lt;span style="color:#40a070">1.4153e-02&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#40a070">1.7975e-02&lt;/span>, &lt;span style="color:#40a070">1.7044e-02&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [ &lt;span style="color:#40a070">3.9215e-03&lt;/span>, &lt;span style="color:#40a070">2.7733e-03&lt;/span>, &lt;span style="color:#40a070">3.5736e-02&lt;/span>, &lt;span style="color:#666">...&lt;/span>, &lt;span style="color:#40a070">3.4088e-02&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#40a070">5.6534e-03&lt;/span>, &lt;span style="color:#666">-&lt;/span>&lt;span style="color:#40a070">7.3547e-02&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [ &lt;span style="color:#40a070">1.0864e-02&lt;/span>, &lt;span style="color:#666">-&lt;/span>&lt;span style="color:#40a070">4.7424e-02&lt;/span>, &lt;span style="color:#666">-&lt;/span>&lt;span style="color:#40a070">9.4452e-03&lt;/span>, &lt;span style="color:#666">...&lt;/span>, &lt;span style="color:#666">-&lt;/span>&lt;span style="color:#40a070">2.4048e-02&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#666">-&lt;/span>&lt;span style="color:#40a070">3.8862e-05&lt;/span>, &lt;span style="color:#666">-&lt;/span>&lt;span style="color:#40a070">1.5249e-03&lt;/span>]]], grad_fn&lt;span style="color:#666">=&amp;lt;&lt;/span>EmbeddingBackward0&lt;span style="color:#666">&amp;gt;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>But seeing the tokenized input translated into the embedding (that we eventually pass to the LLM) reveals something interesting. Although the embeddings &lt;strong>are a discrete and fixed size&lt;/strong>, the value of each dimension within the embedding &lt;strong>is a continuous value&lt;/strong>.&lt;/p>
&lt;p>Continuous values are a little more intuitive to work with when looking back at the original question, &amp;quot;can you give a distribution as an input&amp;quot;. Let's see if if we can exploit these values to some use&lt;/p>
&lt;h2 id="looks-similar">Looks similar...&lt;/h2>
&lt;p>The most common way to exploit embeddings is to find other embeddings using various distance metrics. Different ways of interpreting the distance or difference between the embedding vectors hopefully translates into semantically (human) meaningful results.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#007020;font-weight:bold">import&lt;/span> &lt;span style="color:#0e84b5;font-weight:bold">torch&lt;/span>&lt;span style="color:#666">,&lt;/span> &lt;span style="color:#0e84b5;font-weight:bold">torch.nn.functional&lt;/span> &lt;span style="color:#007020;font-weight:bold">as&lt;/span> &lt;span style="color:#0e84b5;font-weight:bold">F&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>tokenizer &lt;span style="color:#666">=&lt;/span> AutoTokenizer&lt;span style="color:#666">.&lt;/span>from_pretrained(&lt;span style="color:#4070a0">&amp;#34;microsoft/phi-2&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>model &lt;span style="color:#666">=&lt;/span> AutoModelForCausalLM&lt;span style="color:#666">.&lt;/span>from_pretrained(&lt;span style="color:#4070a0">&amp;#34;microsoft/phi-2&amp;#34;&lt;/span>)&lt;span style="color:#666">.&lt;/span>to(device)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#60a0b0;font-style:italic"># get the embedding matrix&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>W &lt;span style="color:#666">=&lt;/span> model&lt;span style="color:#666">.&lt;/span>get_input_embeddings()&lt;span style="color:#666">.&lt;/span>weight
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#007020;font-weight:bold">def&lt;/span> &lt;span style="color:#06287e">top_bottom_sim&lt;/span>(word, k&lt;span style="color:#666">=&lt;/span>&lt;span style="color:#40a070">5&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> i &lt;span style="color:#666">=&lt;/span> tokenizer&lt;span style="color:#666">.&lt;/span>encode(word, add_special_tokens&lt;span style="color:#666">=&lt;/span>&lt;span style="color:#007020;font-weight:bold">False&lt;/span>)[&lt;span style="color:#40a070">0&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#60a0b0;font-style:italic"># get similarity to all other embeddings&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> s &lt;span style="color:#666">=&lt;/span> F&lt;span style="color:#666">.&lt;/span>cosine_similarity(W[i]&lt;span style="color:#666">.&lt;/span>unsqueeze(&lt;span style="color:#40a070">0&lt;/span>), W, dim&lt;span style="color:#666">=&lt;/span>&lt;span style="color:#40a070">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> topv, topi &lt;span style="color:#666">=&lt;/span> torch&lt;span style="color:#666">.&lt;/span>topk(s, k&lt;span style="color:#666">+&lt;/span>&lt;span style="color:#40a070">1&lt;/span>) &lt;span style="color:#60a0b0;font-style:italic"># pick the most similar&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> botv, boti &lt;span style="color:#666">=&lt;/span> torch&lt;span style="color:#666">.&lt;/span>topk(&lt;span style="color:#666">-&lt;/span>s, k) &lt;span style="color:#60a0b0;font-style:italic"># pick the least similar&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020">print&lt;/span>(&lt;span style="color:#4070a0">&amp;#34;Top:&amp;#34;&lt;/span>, [(tokenizer&lt;span style="color:#666">.&lt;/span>decode([ix&lt;span style="color:#666">.&lt;/span>item()]), &lt;span style="color:#007020">round&lt;/span>(val&lt;span style="color:#666">.&lt;/span>item(),&lt;span style="color:#40a070">3&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">for&lt;/span> val, ix &lt;span style="color:#007020;font-weight:bold">in&lt;/span> &lt;span style="color:#007020">zip&lt;/span>(topv[&lt;span style="color:#40a070">1&lt;/span>:], topi[&lt;span style="color:#40a070">1&lt;/span>:])])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020">print&lt;/span>(&lt;span style="color:#4070a0">&amp;#34;Bottom:&amp;#34;&lt;/span>, [(tokenizer&lt;span style="color:#666">.&lt;/span>decode([ix&lt;span style="color:#666">.&lt;/span>item()]), &lt;span style="color:#007020">round&lt;/span>(&lt;span style="color:#666">-&lt;/span>val&lt;span style="color:#666">.&lt;/span>item(),&lt;span style="color:#40a070">3&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">for&lt;/span> val, ix &lt;span style="color:#007020;font-weight:bold">in&lt;/span> &lt;span style="color:#007020">zip&lt;/span>(botv, boti)])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>top_bottom_sim(&lt;span style="color:#4070a0">&amp;#34;question&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#60a0b0;font-style:italic">## output&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Top: [(&lt;span style="color:#4070a0">&amp;#39; question&amp;#39;&lt;/span>, &lt;span style="color:#40a070">0.187&lt;/span>), (&lt;span style="color:#4070a0">&amp;#39; Question&amp;#39;&lt;/span>, &lt;span style="color:#40a070">0.161&lt;/span>), (&lt;span style="color:#4070a0">&amp;#39;Question&amp;#39;&lt;/span>, &lt;span style="color:#40a070">0.15&lt;/span>), (&lt;span style="color:#4070a0">&amp;#39;problem&amp;#39;&lt;/span>, &lt;span style="color:#40a070">0.139&lt;/span>), (&lt;span style="color:#4070a0">&amp;#39; questions&amp;#39;&lt;/span>, &lt;span style="color:#40a070">0.138&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Bottom: [(&lt;span style="color:#4070a0">&amp;#39; Ember&amp;#39;&lt;/span>, &lt;span style="color:#666">-&lt;/span>&lt;span style="color:#40a070">0.082&lt;/span>), (&lt;span style="color:#4070a0">&amp;#39; fetal&amp;#39;&lt;/span>, &lt;span style="color:#666">-&lt;/span>&lt;span style="color:#40a070">0.081&lt;/span>), (&lt;span style="color:#4070a0">&amp;#39; Union&amp;#39;&lt;/span>, &lt;span style="color:#666">-&lt;/span>&lt;span style="color:#40a070">0.08&lt;/span>), (&lt;span style="color:#4070a0">&amp;#39; Moss&amp;#39;&lt;/span>, &lt;span style="color:#666">-&lt;/span>&lt;span style="color:#40a070">0.076&lt;/span>), (&lt;span style="color:#4070a0">&amp;#39; expired&amp;#39;&lt;/span>, &lt;span style="color:#666">-&lt;/span>&lt;span style="color:#40a070">0.074&lt;/span>)]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The code above is a simple example to find 5 most similar and dissimilar tokens to &amp;quot;question&amp;quot;. Here &amp;quot;similarity&amp;quot; is defined as the &lt;a href="https://en.wikipedia.org/wiki/Cosine_similarity">cosine similarity&lt;/a>. I like to think of it as the angle between vectors: the smaller the angle the more &amp;quot;similar&amp;quot; the vectors.&lt;/p>
&lt;p>There's many ways to derive these embedding matrices to position tokens in a space that allow for these kinds of similarity measurements. Very roughly the &amp;quot;reason&amp;quot; this works is that &amp;quot;similar&amp;quot; words are surrounded by other &amp;quot;similar&amp;quot; words in training data. That is to say, the token &lt;strong>&amp;quot;question&amp;quot;&lt;/strong>, tends to appear in the same places as &lt;strong>&amp;quot;Question&amp;quot;&lt;/strong> (capitalization matters!), and, apparently, around the same places as &lt;strong>&amp;quot;problem&amp;quot;&lt;/strong> (which also probably makes intuitive sense). The &lt;a href="https://en.wikipedia.org/wiki/Word2vec">Word2Vec&lt;/a> algorithm and paper is a great read for this.&lt;/p>
&lt;h2 id="what-does-this-have-to-do-with-distribution-as-input">What does this have to do with distribution as input?&lt;/h2>
&lt;p>Returning to the original question, can you give an LLM a distribution as an input?&lt;/p>
&lt;p>Although the answer is ~~no, we do see that the vector representation of the input tokens are something we can manipulate. Above we've used the representations for the most basic usage, similarity, but we can also directly multiply, add, or blend these vectors together &lt;strong>and pass those&lt;/strong> as input to the LLM instead.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#60a0b0;font-style:italic"># Blend each token with the average of its 5 nearest neighbors&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#007020;font-weight:bold">def&lt;/span> &lt;span style="color:#06287e">blend_tokens&lt;/span>(tokens):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> blended &lt;span style="color:#666">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">for&lt;/span> tid &lt;span style="color:#007020;font-weight:bold">in&lt;/span> tokens:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sims &lt;span style="color:#666">=&lt;/span> F&lt;span style="color:#666">.&lt;/span>cosine_similarity(W[tid]&lt;span style="color:#666">.&lt;/span>unsqueeze(&lt;span style="color:#40a070">0&lt;/span>), W, dim&lt;span style="color:#666">=&lt;/span>&lt;span style="color:#40a070">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> _, top_idx &lt;span style="color:#666">=&lt;/span> torch&lt;span style="color:#666">.&lt;/span>topk(sims, &lt;span style="color:#40a070">6&lt;/span>) &lt;span style="color:#60a0b0;font-style:italic"># token itself + 5 neighbors&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> blended&lt;span style="color:#666">.&lt;/span>append(W[top_idx[&lt;span style="color:#40a070">1&lt;/span>:]]&lt;span style="color:#666">.&lt;/span>mean(dim&lt;span style="color:#666">=&lt;/span>&lt;span style="color:#40a070">0&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">return&lt;/span> torch&lt;span style="color:#666">.&lt;/span>stack(blended)&lt;span style="color:#666">.&lt;/span>unsqueeze(&lt;span style="color:#40a070">0&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#60a0b0;font-style:italic"># Example&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>text &lt;span style="color:#666">=&lt;/span> &lt;span style="color:#4070a0">&amp;#34;Dumb question here&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>input_ids &lt;span style="color:#666">=&lt;/span> tokenizer&lt;span style="color:#666">.&lt;/span>encode(text, return_tensors&lt;span style="color:#666">=&lt;/span>&lt;span style="color:#4070a0">&amp;#34;pt&amp;#34;&lt;/span>)&lt;span style="color:#666">.&lt;/span>to(model&lt;span style="color:#666">.&lt;/span>device)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#60a0b0;font-style:italic"># Generate from original&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>original_output &lt;span style="color:#666">=&lt;/span> model&lt;span style="color:#666">.&lt;/span>generate(input_ids, max_new_tokens&lt;span style="color:#666">=&lt;/span>&lt;span style="color:#40a070">10&lt;/span>, pad_token_id&lt;span style="color:#666">=&lt;/span>tokenizer&lt;span style="color:#666">.&lt;/span>eos_token_id)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#007020">print&lt;/span>(&lt;span style="color:#4070a0">&amp;#34;&lt;/span>&lt;span style="color:#4070a0;font-weight:bold">\n&lt;/span>&lt;span style="color:#4070a0">Original: &amp;#34;&lt;/span>, tokenizer&lt;span style="color:#666">.&lt;/span>decode(original_output[&lt;span style="color:#40a070">0&lt;/span>]))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#60a0b0;font-style:italic"># Generate from blended&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>blended_emb &lt;span style="color:#666">=&lt;/span> blend_tokens(input_ids[&lt;span style="color:#40a070">0&lt;/span>])&lt;span style="color:#666">.&lt;/span>to(model&lt;span style="color:#666">.&lt;/span>device)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>blended_output &lt;span style="color:#666">=&lt;/span> model&lt;span style="color:#666">.&lt;/span>generate(inputs_embeds&lt;span style="color:#666">=&lt;/span>blended_emb, max_new_tokens&lt;span style="color:#666">=&lt;/span>&lt;span style="color:#40a070">10&lt;/span>, pad_token_id&lt;span style="color:#666">=&lt;/span>tokenizer&lt;span style="color:#666">.&lt;/span>eos_token_id)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#007020">print&lt;/span>(&lt;span style="color:#4070a0">&amp;#34;&lt;/span>&lt;span style="color:#4070a0;font-weight:bold">\n&lt;/span>&lt;span style="color:#4070a0">Blended:&amp;#34;&lt;/span>, tokenizer&lt;span style="color:#666">.&lt;/span>decode(blended_output[&lt;span style="color:#40a070">0&lt;/span>]))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#60a0b0;font-style:italic">## output&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Original: Dumb question here, but I&lt;span style="color:#4070a0">&amp;#39;m not sure how to do it&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Blended: Dumb question here&lt;span style="color:#666">.&lt;/span> I&lt;span style="color:#4070a0">&amp;#39;m not sure what you mean by&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>We can see in the output from the blended example is not the same as the original input, which demonstrates that the LLM can still yield interesting results after manipulating the input embeddings that don't have an exact &amp;quot;meaning&amp;quot;.&lt;/p>
&lt;p>&lt;code>blend_tokens&lt;/code> averages each of the input tokens with the 5 most &amp;quot;similar&amp;quot; tokens to them. If we were to look these up in our embedding matrix it wouldn't translate to an explicit token.&lt;/p>
&lt;p>This is how we move towards a &amp;quot;distribution as an input&amp;quot;: by doing some preprocessing on the input vectors before passing them to the LLM.&lt;/p>
&lt;h2 id="now-what">Now what?&lt;/h2>
&lt;p>I'm actually not sure. I just stumbled into this because of the original question. I think a next step could be to explore potential ways to manipulate the input embeddings, we only tried averaging here, which probably isn't very meaningful.&lt;/p>
&lt;p>Another thing is that I don't think API providers allow raw vector inputs, they tokenize the input text themselves, so we couldn't do this experiment with those.&lt;/p>
&lt;p>It's possible we could use this technique to &amp;quot;find&amp;quot; other tokens that might have interesting output, and pass those instead to the API providers. This sounds a little like adversarial input research related... I suppose that's an exercise left for the reader.&lt;/p></description></item><item><title>RIP flatMapGroupsWithState</title><link>https://nickkarpov.com/2025/transform-with-state/</link><pubDate>Thu, 27 Feb 2025 01:00:00 +0000</pubDate><guid>https://nickkarpov.com/2025/transform-with-state/</guid><description>&lt;p>The new &lt;code>transformWithState&lt;/code> API is now available on &lt;a href="https://www.databricks.com/blog/introducing-transformwithstate-apache-sparktm-structured-streaming">Databricks Runtime 16.2&lt;/a> and you'd be crazy not to &lt;a href="https://docs.databricks.com/aws/en/stateful-applications/">try it&lt;/a>.&lt;/p>
&lt;p>The improvements over the old &lt;code>flatMapGroupsWithState&lt;/code> and &lt;code>applyInPandasWithState&lt;/code> approaches to handling custom state are compelling from an API perspective and &lt;strong>a total no brainer for performance&lt;/strong>.&lt;/p>
&lt;p>Here's a stab at migrating a simple PySpark Streaming job to use &lt;code>transformWithState&lt;/code> with some inline commentary that highlight the relevant API improvements and performance implications.&lt;/p>
&lt;h2 id="why-applyinpandaswithstate-and-flatmapgroupswithstate-suck">Why applyInPandasWithState and flatMapGroupsWithState suck&lt;/h2>
&lt;p>Here's a simple streaming operator written with the old &lt;code>applyInPandasWithState&lt;/code> API. It's job is to aggregate events for a fleet of delivery vehicles and write them out to a table only when the vehicle sends a &lt;code>delivered&lt;/code> event.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#60a0b0;font-style:italic"># our aggregating function that takes:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#60a0b0;font-style:italic"># - key (grouping key)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#60a0b0;font-style:italic"># - pdf_iter (rows that belong to the key)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#60a0b0;font-style:italic"># - state (arbitrary state object for the key)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#007020;font-weight:bold">def&lt;/span> &lt;span style="color:#06287e">stateful_accumulate&lt;/span>(key, pdf_iter, state: GroupState):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">if&lt;/span> state&lt;span style="color:#666">.&lt;/span>exists:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> stored_tuple &lt;span style="color:#666">=&lt;/span> state&lt;span style="color:#666">.&lt;/span>get
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> current_events &lt;span style="color:#666">=&lt;/span> stored_tuple[&lt;span style="color:#40a070">0&lt;/span>] &lt;span style="color:#007020;font-weight:bold">if&lt;/span> stored_tuple[&lt;span style="color:#40a070">0&lt;/span>] &lt;span style="color:#007020;font-weight:bold">else&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">else&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> current_events &lt;span style="color:#666">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">for&lt;/span> pdf &lt;span style="color:#007020;font-weight:bold">in&lt;/span> pdf_iter:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> current_events&lt;span style="color:#666">.&lt;/span>extend(pdf&lt;span style="color:#666">.&lt;/span>to_dict(&lt;span style="color:#4070a0">&amp;#34;records&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">if&lt;/span> &lt;span style="color:#007020">any&lt;/span>(e[&lt;span style="color:#4070a0">&amp;#34;type&amp;#34;&lt;/span>] &lt;span style="color:#666">==&lt;/span> &lt;span style="color:#4070a0">&amp;#34;delivered&amp;#34;&lt;/span> &lt;span style="color:#007020;font-weight:bold">for&lt;/span> e &lt;span style="color:#007020;font-weight:bold">in&lt;/span> current_events):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">yield&lt;/span> pd&lt;span style="color:#666">.&lt;/span>DataFrame([{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#4070a0">&amp;#34;orderid&amp;#34;&lt;/span>: key[&lt;span style="color:#40a070">0&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#4070a0">&amp;#34;events&amp;#34;&lt;/span>: current_events
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> state&lt;span style="color:#666">.&lt;/span>remove()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">else&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> state&lt;span style="color:#666">.&lt;/span>update((current_events,))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#60a0b0;font-style:italic"># we read from an append only table&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#666">=&lt;/span> spark&lt;span style="color:#666">.&lt;/span>readStream&lt;span style="color:#666">.&lt;/span>table(&lt;span style="color:#4070a0">&amp;#34;orders.default.events&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#60a0b0;font-style:italic"># define our stream to group by orderid and apply the above stateful_accumulate function&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>aggregateFleetEvents &lt;span style="color:#666">=&lt;/span> df&lt;span style="color:#666">.&lt;/span>groupBy(&lt;span style="color:#4070a0">&amp;#34;orderid&amp;#34;&lt;/span>)&lt;span style="color:#666">.&lt;/span>applyInPandasWithState(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> func&lt;span style="color:#666">=&lt;/span>stateful_accumulate,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> outputStructType&lt;span style="color:#666">=&lt;/span>output_schema,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> stateStructType&lt;span style="color:#666">=&lt;/span>state_schema,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> outputMode&lt;span style="color:#666">=&lt;/span>&lt;span style="color:#4070a0">&amp;#34;append&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> timeoutConf&lt;span style="color:#666">=&lt;/span>&lt;span style="color:#4070a0">&amp;#34;NoTimeout&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#60a0b0;font-style:italic"># flush our stream to the target table&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>aggregateFleetEvents&lt;span style="color:#666">.&lt;/span>writeStream&lt;span style="color:#666">.&lt;/span>toTable(&lt;span style="color:#4070a0">&amp;#34;orders.default.drives&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The logic in &lt;code>stateful_accumulate&lt;/code> works fine, but there are some issues...&lt;/p>
&lt;h3 id="no-explicit-state-lifecycle-management">No explicit state lifecycle management&lt;/h3>
&lt;p>The first issue is that we have no state lifecycle separation. The first few lines are mostly concerned with correctly initializing the state object because it's &lt;em>undefined to start&lt;/em>. This looks tolerable for such a simple job but if this was even a little bit more complex the initialization would be a major sore (imagine migrating a job with existing state).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#007020;font-weight:bold">if&lt;/span> state&lt;span style="color:#666">.&lt;/span>exists:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> stored_tuple &lt;span style="color:#666">=&lt;/span> state&lt;span style="color:#666">.&lt;/span>get
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> current_events &lt;span style="color:#666">=&lt;/span> stored_tuple[&lt;span style="color:#40a070">0&lt;/span>] &lt;span style="color:#007020;font-weight:bold">if&lt;/span> stored_tuple[&lt;span style="color:#40a070">0&lt;/span>] &lt;span style="color:#007020;font-weight:bold">else&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#007020;font-weight:bold">else&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> current_events &lt;span style="color:#666">=&lt;/span> []
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="single-state-object">Single state object&lt;/h3>
&lt;p>The second issue is that we have to handle the entire state object at once &lt;em>and&lt;/em> rewrite it entirely. This is subtle for small jobs, but a complete deal breaker if you need to scale. Rewriting the entire state every time new events appear simply doesn't make any sense, especially once we need to track multiple logical states per key.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#60a0b0;font-style:italic"># add new events to `current_events`&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#007020;font-weight:bold">for&lt;/span> pdf &lt;span style="color:#007020;font-weight:bold">in&lt;/span> pdf_iter:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> current_events&lt;span style="color:#666">.&lt;/span>extend(pdf&lt;span style="color:#666">.&lt;/span>to_dict(&lt;span style="color:#4070a0">&amp;#34;records&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#60a0b0;font-style:italic"># ...now current_events = old state + new state&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#007020;font-weight:bold">if&lt;/span> &lt;span style="color:#007020">any&lt;/span>(e[&lt;span style="color:#4070a0">&amp;#34;type&amp;#34;&lt;/span>] &lt;span style="color:#666">==&lt;/span> &lt;span style="color:#4070a0">&amp;#34;delivered&amp;#34;&lt;/span> &lt;span style="color:#007020;font-weight:bold">for&lt;/span> e &lt;span style="color:#007020;font-weight:bold">in&lt;/span> current_events):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">yield&lt;/span> pd&lt;span style="color:#666">.&lt;/span>DataFrame([{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#4070a0">&amp;#34;orderid&amp;#34;&lt;/span>: key[&lt;span style="color:#40a070">0&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#4070a0">&amp;#34;events&amp;#34;&lt;/span>: current_events
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> state&lt;span style="color:#666">.&lt;/span>remove()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#007020;font-weight:bold">else&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#60a0b0;font-style:italic"># &amp;#39;update&amp;#39; the state aka overwrite the ENTIRE state X_X&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> state&lt;span style="color:#666">.&lt;/span>update((current_events,))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="why-transformwithstate-is-better-than-flatmapgroupswithstate-and-applyinpandaswithstate">Why &lt;code>transformWithState&lt;/code> is better than &lt;code>flatMapGroupsWithState&lt;/code> and &lt;code>applyInPandasWithState&lt;/code>&lt;/h2>
&lt;p>Here's the same job rewritten to use &lt;code>transformWithState&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#007020;font-weight:bold">class&lt;/span> &lt;span style="color:#0e84b5;font-weight:bold">DeliveryFleetEventAggregator&lt;/span>(StatefulProcessor):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">def&lt;/span> &lt;span style="color:#06287e">init&lt;/span>(self, handle: StatefulProcessorHandle) &lt;span style="color:#666">-&amp;gt;&lt;/span> &lt;span style="color:#007020;font-weight:bold">None&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#666">.&lt;/span>list_state &lt;span style="color:#666">=&lt;/span> handle&lt;span style="color:#666">.&lt;/span>getListState(stateName&lt;span style="color:#666">=&lt;/span>&lt;span style="color:#4070a0">&amp;#34;listState&amp;#34;&lt;/span>, schema&lt;span style="color:#666">=&lt;/span>event_struct)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">def&lt;/span> &lt;span style="color:#06287e">handleInputRows&lt;/span>(self, key, rows, timerValues) &lt;span style="color:#666">-&amp;gt;&lt;/span> Iterator[pd&lt;span style="color:#666">.&lt;/span>DataFrame]:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> should_flush &lt;span style="color:#666">=&lt;/span> &lt;span style="color:#007020;font-weight:bold">False&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">for&lt;/span> pdf &lt;span style="color:#007020;font-weight:bold">in&lt;/span> rows:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#666">.&lt;/span>list_state&lt;span style="color:#666">.&lt;/span>appendList(pdf)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">if&lt;/span> &lt;span style="color:#4070a0">&amp;#39;delivered&amp;#39;&lt;/span> &lt;span style="color:#007020;font-weight:bold">in&lt;/span> pdf[&lt;span style="color:#4070a0">&amp;#39;type&amp;#39;&lt;/span>]&lt;span style="color:#666">.&lt;/span>values:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> should_flush &lt;span style="color:#666">=&lt;/span> &lt;span style="color:#007020;font-weight:bold">True&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">if&lt;/span> should_flush:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">yield&lt;/span> pd&lt;span style="color:#666">.&lt;/span>DataFrame([{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#4070a0">&amp;#34;orderid&amp;#34;&lt;/span>: key[&lt;span style="color:#40a070">0&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#4070a0">&amp;#34;events&amp;#34;&lt;/span>: &lt;span style="color:#007020">list&lt;/span>(self&lt;span style="color:#666">.&lt;/span>list_state&lt;span style="color:#666">.&lt;/span>get())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#666">.&lt;/span>list_state&lt;span style="color:#666">.&lt;/span>clear()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">def&lt;/span> &lt;span style="color:#06287e">close&lt;/span>(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020">super&lt;/span>()&lt;span style="color:#666">.&lt;/span>close()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>aggregateFleetEvents &lt;span style="color:#666">=&lt;/span> df&lt;span style="color:#666">.&lt;/span>groupBy(&lt;span style="color:#4070a0">&amp;#34;orderid&amp;#34;&lt;/span>)&lt;span style="color:#666">.&lt;/span>transformWithStateInPandas(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> statefulProcessor&lt;span style="color:#666">=&lt;/span>DeliveryFleetEventAggregator(),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> outputStructType&lt;span style="color:#666">=&lt;/span>output_schema,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> outputMode&lt;span style="color:#666">=&lt;/span>&lt;span style="color:#4070a0">&amp;#34;append&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> timeMode&lt;span style="color:#666">=&lt;/span>&lt;span style="color:#4070a0">&amp;#34;none&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Lifecycle methods &lt;code>init&lt;/code> and &lt;code>close&lt;/code> separate setup and teardown concerns from the main processing logic. This is a major improvement in terms of readability and maintainability.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#007020;font-weight:bold">def&lt;/span> &lt;span style="color:#06287e">init&lt;/span>(self, handle: StatefulProcessorHandle) &lt;span style="color:#666">-&amp;gt;&lt;/span> &lt;span style="color:#007020;font-weight:bold">None&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#666">.&lt;/span>list_state &lt;span style="color:#666">=&lt;/span> handle&lt;span style="color:#666">.&lt;/span>getListState(stateName&lt;span style="color:#666">=&lt;/span>&lt;span style="color:#4070a0">&amp;#34;listState&amp;#34;&lt;/span>, schema&lt;span style="color:#666">=&lt;/span>event_struct)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>We have a separate logical state &lt;code>self.list_state&lt;/code> that we initialize with &lt;code>handle.getListState&lt;/code>. This is part of the new composite types capability that also includes &lt;code>ValueState&lt;/code> and &lt;code>MapState&lt;/code>. This apparently small difference has major implications. &lt;a href="https://docs.databricks.com/aws/en/stateful-applications?language=Python#custom-state-types">We can work with multiple separate state objects independently, as needed, &lt;em>and&lt;/em> we get a massive performance boost as a consequence.&lt;/a> The new version only needs to &lt;code>appendList&lt;/code> while taking a single pass over the input rows.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#007020;font-weight:bold">def&lt;/span> &lt;span style="color:#06287e">handleInputRows&lt;/span>(self, key, rows, timerValues) &lt;span style="color:#666">-&amp;gt;&lt;/span> Iterator[pd&lt;span style="color:#666">.&lt;/span>DataFrame]:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> should_flush &lt;span style="color:#666">=&lt;/span> &lt;span style="color:#007020;font-weight:bold">False&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">for&lt;/span> pdf &lt;span style="color:#007020;font-weight:bold">in&lt;/span> rows:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#666">.&lt;/span>list_state&lt;span style="color:#666">.&lt;/span>appendList(pdf)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">if&lt;/span> &lt;span style="color:#4070a0">&amp;#39;delivered&amp;#39;&lt;/span> &lt;span style="color:#007020;font-weight:bold">in&lt;/span> pdf[&lt;span style="color:#4070a0">&amp;#39;type&amp;#39;&lt;/span>]&lt;span style="color:#666">.&lt;/span>values:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> should_flush &lt;span style="color:#666">=&lt;/span> &lt;span style="color:#007020;font-weight:bold">True&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">if&lt;/span> should_flush:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#007020;font-weight:bold">yield&lt;/span> pd&lt;span style="color:#666">.&lt;/span>DataFrame([{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#4070a0">&amp;#34;orderid&amp;#34;&lt;/span>: key[&lt;span style="color:#40a070">0&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#4070a0">&amp;#34;events&amp;#34;&lt;/span>: &lt;span style="color:#007020">list&lt;/span>(self&lt;span style="color:#666">.&lt;/span>list_state&lt;span style="color:#666">.&lt;/span>get())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#666">.&lt;/span>list_state&lt;span style="color:#666">.&lt;/span>clear()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>We don't have any complex timing or expiration needs in this simple job but &lt;code>transformWithState&lt;/code> supports some awesome features like defining timers for custom logic and setting TTL for automatic state eviction, giving you &lt;a href="https://docs.databricks.com/aws/en/stateful-applications/#program-timed-events">fine-grained control over how and when your state data is updated or removed.&lt;/a>.&lt;/p>
&lt;p>You'd be crazy not to seriously consider rewriting your old jobs with this new API.&lt;/p></description></item></channel></rss>